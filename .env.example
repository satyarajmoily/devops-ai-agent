# Environment Configuration
ENVIRONMENT=development
LOG_LEVEL=DEBUG
DEBUG=true

# API Configuration
API_HOST=0.0.0.0
API_PORT=8001
API_PREFIX=/api/v1

# Service Configuration
SERVICE_NAME=market-programmer-agent
SERVICE_VERSION=0.1.0

# LLM Configuration (Required for AI analysis)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
LLM_PROVIDER=openai
LLM_MODEL=gpt-4
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4000
LLM_TIMEOUT=60

# External Service Configuration
MARKET_PREDICTOR_URL=http://localhost:8000
PROMETHEUS_URL=http://localhost:9090
LOKI_URL=http://localhost:3100

# GitHub Integration (For future phases)
GITHUB_TOKEN=your_github_token_here
GITHUB_REPOSITORY=your_username/your_repo
ALLOWED_REPOSITORIES=["your_username/repo1","your_username/repo2"]

# Monitoring Configuration
MONITORING_INTERVAL=30
HEALTH_CHECK_TIMEOUT=10
METRICS_CACHE_TTL=60

# Agent Behavior Configuration
MAX_ACTIONS_PER_CYCLE=3
SAFETY_MODE=true
LEARNING_ENABLED=true
# Enable/disable fallback to rule-based analysis when AI fails
# Set to false for pure AI testing (fails if OpenAI unavailable)
# Set to true for production resilience (falls back to rules)
FALLBACK_ENABLED=true

# Testing Configuration
ENABLE_TESTING=true
TEST_TIMEOUT=300